{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-quilt",
   "metadata": {},
   "source": [
    "# PilotNet Sigma-Delta Neural Network (SDNN) Training\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"images/pilotnet_steering_white.png\" alt=\"Drawing\" style=\"height: 200px;\"/> </td>\n",
    "<td> <img src=\"images/25093.jpg\" alt=\"Drawing\" style=\"height: 200px; width:600px\"/> </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<table><tr>\n",
    "<td> <font size=\"+2\"><b>PilotNet:</b> Predict the car's steering angle from the dashboard view. </font></td>\n",
    "</tr>\n",
    "<tr><td> PilotNet dataset is available freely <a href=\"https://github.com/lhzlhz/PilotNet/tree/master/data/datasets\">here</a>. © MIT License.\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "## What are SDNNs?\n",
    "<table><tr>\n",
    "<td> <img src=\"images/delta_encoder.png\" alt=\"Drawing\" style=\"height: 200px;\"/> </td>\n",
    "<td> <img src=\"images/sigma_decoder.png\" alt=\"Drawing\" style=\"height: 200px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "__Sigma-delta neural networks__ consists of two main units: _sigma_ decoder in the dendrite and _delta_ encoder in the axon. Delta encoder uses differential encoding on the output activation of a regular ANN activation, for e.g. ReLU. In addition it only sends activation to the next layer when the encoded message magnitude is larger than its threshold. The sigma unit accumulates the sparse event messages and accumulates it to restore the original value.\n",
    "\n",
    "<table><tr>\n",
    "<!-- <td> <img src=\"images/sdnn.png\" alt=\"Drawing\" style=\"height: 300px;\"/> </td> -->\n",
    "<td> <img src=\"./images/sdnn.png\" height=\"300\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "A sigma-delta neuron is simply a regular activation wrapped around by a sigma unit at it's input and a delta unit at its output.\n",
    "\n",
    "When the input to the network is a temporal sequence, the activations do not change much. Therefore, the message between the layers are reduced which in turn reduces the synaptic computation in the next layer. In addition, the graded event values can encode the change in magnitude in one time-step. Therefore there is no increase in latency at the cost of time-steps unlike the rate coded Spiking Neural Networks.\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"images/temporal_redundancy.png\" alt=\"Drawing\" style=\"height: 170px;\"/> </td>\n",
    "<td> <img src=\"images/sdnn_reconstruction.png\" alt=\"Drawing\" style=\"height: 170px;\"/> </td>\n",
    "</tr><tr>\n",
    "<td> Credit Eadweard Muybridge <a href=\"https://commons.wikimedia.org/wiki/File:Muybridge_race_horse_animated.gif\">© Public Domain</a> </td>\n",
    "</tr></table>\n",
    "\n",
    "<!-- TODO:\n",
    "- Brief Overview of Sigma-Delta Network\n",
    "- Add interesting figure describing SDNN\n",
    "- Advantages of event based sparse computation\n",
    "- Advantages compared to rate coded SNNs\n",
    "- When are they useful -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mature-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "from pilotnet_dataset import PilotNetDataset\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expressed-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff436a4cf70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(4205)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-strength",
   "metadata": {},
   "source": [
    "# Event sparsity loss\n",
    "\n",
    "Sparsity loss to penalize the network for high event-rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_rate_loss(x, max_rate=0.01):\n",
    "    mean_event_rate = torch.mean(torch.abs(x))\n",
    "    return F.mse_loss(F.relu(mean_event_rate - max_rate), torch.zeros_like(mean_event_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-corrections",
   "metadata": {},
   "source": [
    "# Network description\n",
    "\n",
    "__SLAYER 2.0__ (__`lava.dl.slayer`__) provides a variety of learnable _neuron models_ <!-- (`slayer.neuron.{cuba, rf, ad_lif, __sigma_delta__, ...}`)  --> , _synapses_ <!-- (`slayer.{synapse, complex.synapse}.{dense, conv, pool, convT, unpool}`)  --> _axons_ and _dendrites_ that support quantized training. \n",
    "For easier use, it also provides __`block`__ interface which packages the associated neurons, synapses, axons and dendrite features into a single module. \n",
    "\n",
    "__Sigma-delta blocks__ are available as `slayer.blocks.sigma_delta.{Dense, Conv, Pool, Input, Output, Flatten, ...}` which can be easily composed to create a variety of sequential network descriptions as shown below. The blocks can easily enable _synaptic weight normalization_, _neuron normalization_ as well as provide useful _gradient monitoring_ utility and _hdf5 network export_ utility.\n",
    "\n",
    "<!-- TODO:\n",
    "- Describe how easy it is to describe a network in slayer2.0\n",
    "- Parameter Quantization is automatically handled unless disabled\n",
    "- Weight and neuron normalization\n",
    "- gradient monitoring utility\n",
    "- hdf5 export utility -->\n",
    "\n",
    "These blocks can be used to create a network using standard PyTorch procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mature-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        sdnn_params = { # sigma-delta neuron parameters\n",
    "                'threshold'     : 0.1,    # delta unit threshold\n",
    "                'tau_grad'      : 0.5,    # delta unit surrogate gradient relaxation parameter\n",
    "                'scale_grad'    : 1,      # delta unit surrogate gradient scale parameter\n",
    "                'requires_grad' : True,   # trainable threshold\n",
    "                'shared_param'  : True,   # layer wise threshold\n",
    "                'activation'    : F.relu, # activation function\n",
    "            }\n",
    "        sdnn_cnn_params = { # conv layer has additional mean only batch norm\n",
    "                **sdnn_params,                                 # copy all sdnn_params\n",
    "                'norm' : slayer.neuron.norm.MeanOnlyBatchNorm, # mean only quantized batch normalizaton\n",
    "            }\n",
    "        sdnn_dense_params = { # dense layers have additional dropout units enabled\n",
    "                **sdnn_cnn_params,                        # copy all sdnn_cnn_params\n",
    "                'dropout' : slayer.neuron.Dropout(p=0.2), # neuron dropout\n",
    "            }\n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList([# sequential network blocks \n",
    "                # delta encoding of the input\n",
    "                slayer.block.sigma_delta.Input(sdnn_params), \n",
    "                # convolution layers\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params,  3, 24, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 24, 36, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 36, 64, 3, padding=(1, 0), stride=(2, 1), weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 64, 64, 3, padding=0, stride=1, weight_scale=2, weight_norm=True),\n",
    "                # flatten layer\n",
    "                slayer.block.sigma_delta.Flatten(),\n",
    "                # dense layers\n",
    "                slayer.block.sigma_delta.Dense(sdnn_dense_params, 64*40, 100, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Dense(sdnn_dense_params,   100,  50, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Dense(sdnn_dense_params,    50,  10, weight_scale=2, weight_norm=True),\n",
    "                # linear readout with sigma decoding of output\n",
    "                slayer.block.sigma_delta.Output(sdnn_dense_params,   10,   1, weight_scale=2, weight_norm=True)\n",
    "            ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        count = []\n",
    "        event_cost = 0\n",
    "\n",
    "        for block in self.blocks: \n",
    "            # forward computation is as simple as calling the blocks in a loop\n",
    "            x = block(x)\n",
    "            if hasattr(block, 'neuron'):\n",
    "                event_cost += event_rate_loss(x)\n",
    "                count.append(torch.sum(torch.abs((x[..., 1:]) > 0).to(x.dtype)).item())\n",
    "\n",
    "        return x, event_cost, torch.FloatTensor(count).reshape((1, -1)).to(x.device)\n",
    "\n",
    "    def grad_flow(self, path):\n",
    "        # helps monitor the gradient flow\n",
    "        grad = [b.synapse.grad_norm for b in self.blocks if hasattr(b, 'synapse')]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.semilogy(grad)\n",
    "        plt.savefig(path + 'gradFlow.png')\n",
    "        plt.close()\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-willow",
   "metadata": {},
   "source": [
    "# Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brown-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = 128  # batch size\n",
    "lr     = 0.01 # leaerning rate\n",
    "lam    = 0.3  # lagrangian for event rate loss\n",
    "epochs = 400  # training epochs\n",
    "steps  = [120, 240, 320] # learning rate reduction milestones\n",
    "\n",
    "trained_folder = 'Trained'\n",
    "logs_folder = 'Logs'\n",
    "\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "os.makedirs(logs_folder   , exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-spring",
   "metadata": {},
   "source": [
    "# Instantiate Network, Optimizer, Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exposed-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# Datasets\n",
    "training_set = PilotNetDataset(\n",
    "    train=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([33, 100]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]), \n",
    ")\n",
    "testing_set = PilotNetDataset(\n",
    "    train=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([33, 100]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch, shuffle=True, num_workers=8)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)\n",
    "\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(\n",
    "        net=net,\n",
    "        error=lambda output, target: F.mse_loss(output.flatten(), target.flatten()),\n",
    "        optimizer=optimizer,\n",
    "        stats=stats,\n",
    "        count_log=True,\n",
    "        lam=lam\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-comfort",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Training loop mainly consists of looping over epochs and calling `assistant.train` and `assistant.test` utilities over training and testing dataset. The `assistant` utility takes care of statndard backpropagation procedure internally.\n",
    "\n",
    "* `stats` can be used in print statement to get formatted stats printout.\n",
    "* `stats.testing.best_loss` can be used to find out if the current iteration has the best testing loss. Here, we use it to save the best model.\n",
    "* `stats.update()` updates the stats collected for the epoch.\n",
    "* `stats.save` saves the stats in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "antique-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   3/4] Train loss =     0.27757 (min =     0.28596) | Test  loss =     0.17090 (min =     0.17329)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    if epoch in steps:    assistant.step_lr()\n",
    "        \n",
    "    for i, (input, ground_truth) in enumerate(train_loader): # training loop\n",
    "        assistant.train(input, ground_truth)\n",
    "        print(f'\\r[Epoch {epoch:3d}/{epochs}] {stats}', end='')\n",
    "    \n",
    "    for i, (input, ground_truth) in enumerate(test_loader): # testing loop\n",
    "        assistant.test(input, ground_truth)\n",
    "        print(f'\\r[Epoch {epoch:3d}/{epochs}] {stats}', end='')\n",
    "        \n",
    "    if epoch%50==49: print() \n",
    "    if stats.testing.best_loss:  \n",
    "        torch.save(net.state_dict(), trained_folder + '/network.pt')\n",
    "    stats.update()\n",
    "    stats.save(trained_folder + '/')\n",
    "    \n",
    "    # gradient flow monitoring\n",
    "    net.grad_flow(trained_folder + '/')\n",
    "    \n",
    "    # checkpoint saves\n",
    "    if epoch%10 == 0:\n",
    "        torch.save({'net': net.state_dict(), 'optimizer': optimizer.state_dict()}, logs_folder + f'/checkpoint{epoch}.pt')                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-float",
   "metadata": {},
   "source": [
    "# Learning plots.\n",
    "\n",
    "Plotting the learning curves is as easy as calling `stats.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "boolean-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-monday",
   "metadata": {},
   "source": [
    "# Export the best trained model\n",
    "\n",
    "Load the best model during training and export it as hdf5 network. It is supported by `lava.lib.dl.netx` to automatically load the network as a lava process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "maritime-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(trained_folder + '/network.pt'))\n",
    "net.export_hdf5(trained_folder + '/network.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-quilt",
   "metadata": {},
   "source": [
    "# Operation count of trained model\n",
    "\n",
    "Here, we compare the synaptic operation and neuron activity of the trained SDNN and an ANN of iso-architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-technical",
   "metadata": {},
   "source": [
    "## Event statistics on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southeast-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event count : 616.1818, 512.5345, 63.0521, 36.2170, 19.6436, 1.3430, 0.4873, 0.1503, 0.5212 | loss =     0.17090 (min =     0.17090)"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for i, (input, ground_truth) in enumerate(test_loader):\n",
    "    _, count = assistant.test(input, ground_truth)\n",
    "    count = (count.flatten()/ (input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n",
    "    counts.append(count) \n",
    "    print('\\rEvent count : ' + ', '.join([f'{c:.4f}' for c in count]), f'| {stats.testing}', end='') \n",
    "        \n",
    "counts = np.mean(counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a30a5d3-f986-4ba0-8062-446a9fd1da33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant.lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-sight",
   "metadata": {},
   "source": [
    "# Event and Synops comparion with ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reasonable-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----------------------------------------------------------------------------|\n",
      "|                         |          SDNN           |           ANN           |\n",
      "|-----------------------------------------------------------------------------|\n",
      "|         |     Shape     |  Events  |    Synops    | Activations|    MACs    |\n",
      "|-----------------------------------------------------------------------------|\n",
      "| layer-0 | (100, 33,  3) |   625.87 |              |       9900 |            |\n",
      "| layer-1 | ( 49, 16, 24) |   504.28 |     33796.96 |      18816 |     534600 |\n",
      "| layer-2 | ( 24,  7, 36) |    62.79 |     40846.38 |       6048 |    1524096 |\n",
      "| layer-3 | ( 22,  4, 64) |    36.68 |     18082.68 |       5632 |    1741824 |\n",
      "| layer-4 | ( 20,  2, 64) |    20.06 |     21129.40 |       2560 |    3244032 |\n",
      "| layer-5 | (  1,  1,100) |     1.38 |      2005.62 |        100 |     256000 |\n",
      "| layer-6 | (  1,  1, 50) |     0.51 |        68.83 |         50 |       5000 |\n",
      "| layer-7 | (  1,  1, 10) |     0.16 |         5.07 |         10 |        500 |\n",
      "| layer-8 | (  1,  1,  1) |     0.63 |         0.16 |          1 |         10 |\n",
      "|-----------------------------------------------------------------------------|\n",
      "|  Total  |               |  1252.34 |    115935.09 |      43117 |    7306062 |\n",
      "|-----------------------------------------------------------------------------|\n",
      "\n",
      "\n",
      "MSE            : 0.1709 sq. radians\n",
      "Total neurons  : 43117\n",
      "Events sparsity: 34.43x\n",
      "Synops sparsity: 63.02x\n"
     ]
    }
   ],
   "source": [
    "utils.compare_ops(net, counts, mse=stats.testing.min_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
