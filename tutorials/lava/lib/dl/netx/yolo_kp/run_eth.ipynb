{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc75815f-8370-4355-bd5a-67969bd03c4f",
   "metadata": {},
   "source": [
    "# YOLO-KP SDNN Example\n",
    "\n",
    "This tutorial demonstrates the inference of YOLO-KP SDNN (training example scripts [here](https://github.com/lava-nc/lava-dl/tree/main/tutorials/lava/lib/dl/slayer/tiny_yolo_sdnn)) on both CPU and Loihi 2 neurocore.\n",
    "\n",
    "![image](https://github.com/lava-nc/lava/assets/29907126/61057e64-71b3-4ab8-a7ea-39d0cdbac70d)\n",
    "\n",
    "YOLO-KP is a fully convolutional single-headed variant of TinyYOLOv3 object detection architecture specifically designed for 8 chip Loihi 2 form factor called Kapoho Point (KP). The inference example uses the following lava components\n",
    "\n",
    "1. __Network on Loihi 2:__ YOLO-KP network generated from its NetX description. It is a hierarchical network consisting of all the layers of YOLO-KP. This is the portion that runs on Loihi.\n",
    "2. __Data sparsification on SuperHost:__ Delta encoder process that performs frame difference to sparsify the input being communicated to the YOLO-KP network. This process runs on Python.\n",
    "3. __Data communication in and out of lava processes:__ `Injector` process to send raw input to the lava network and `Extractor` process to receive raw output of YOLO-KP. These processes run on Python.\n",
    "4. __Data relay in and out of Loihi chip:__ Input and output adapter process which relay the communication into the chip and out of the chip. Since YOLO-KP is fully convolutional, the adapters translate to/from python spike and Loihi convolution spike.\n",
    "\n",
    "> ℹ️ This example currently does not make use of high speed IO capabilities of Loihi and hence the execution is slow. Once the software support is enabled in Lava, these adapters will not be required and shall be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56595d79-183f-4b78-a000-e8fbefcfd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg, Loihi2SimCfg\n",
    "from lava.proc import io\n",
    "\n",
    "from lava.lib.dl import netx\n",
    "from lava.lib.dl import slayer\n",
    "from lava.lib.dl.slayer import obd\n",
    "\n",
    "from utils import DataGenerator, YOLOPredictor, nms, YOLOMonitor, DeltaEncoder\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb22d4-d01b-4219-a106-d7ce40c750b3",
   "metadata": {},
   "source": [
    "# Import modules for Loihi2 execution\n",
    "\n",
    "Check if Loihi2 compiler is available and import related modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08beb08c-b9a2-44e1-ad63-d2fa9f2cfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lava.utils.system import Loihi2\n",
    "# Loihi2.preferred_partition = 'loihi'\n",
    "# loihi2_is_available = Loihi2.is_loihi2_available\n",
    "os.environ[\"LOIHI_GEN\"] = \"N3C1\"\n",
    "os.environ[\"NXSDKHOST\"] = \"ncl-gdc-vpx-01.zpn.intel.com\"\n",
    "os.environ[\"NXOPTIONS\"] = \"--pio-cfg-chip=0x4191\"\n",
    "\n",
    "# MAKE SURE TO LAUNCH Jupyter using cap_net_raw\n",
    "# nohup /home/sshresth/lava-vpx/frameworks.ai.lava.lava-loihi/utils/cap_net_raw jupyter lab --no-browser &\n",
    "#\n",
    "# SAME GOES FOR python script\n",
    "# /home/sshresth/lava-vpx/frameworks.ai.lava.lava-loihi/utils/cap_net_raw python <script>.py\n",
    "\n",
    "loihi2_is_available = True\n",
    "\n",
    "if loihi2_is_available:\n",
    "    # print(f'Running on {Loihi2.partition}')\n",
    "    from lava.magma.compiler.subcompilers.nc.ncproc_compiler import CompilerOptions\n",
    "    CompilerOptions.verbose = True\n",
    "else:\n",
    "    print(\"Loihi2 compiler is not available in this system. \"\n",
    "          \"This tutorial will execute on CPU backend.\")\n",
    "compression = io.encoder.Compression.DENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b3f8a-3405-496a-bae8-c5e3c4bac788",
   "metadata": {},
   "source": [
    "## Set execution parameters\n",
    "\n",
    "The network execution parameters can be divided into three categories:\n",
    "\n",
    "1. __Model parameters:__ these are parameters of the YOLO model used for the training and shall be reused to replicate the same behavior during inference.\n",
    "2. __Inference parametrs:__ these are parameters just for the inference.\n",
    "3. __Data processing parameters:__ these are parameters need to perform _pre_ and _post_ processing before the input and on the output of the network respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdb59a7-04ae-4a5f-89a1-7b3fcb81750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model arguments\n",
    "trained_folder = os.path.abspath('../../slayer/tiny_yolo_sdnn/Trained_yolo_kp')\n",
    "with open(trained_folder + '/args.txt', 'rt') as f:\n",
    "    model_args = slayer.utils.dotdict(yaml.safe_load(f))\n",
    "\n",
    "# Additional inference arguments\n",
    "inference_args = slayer.utils.dotdict(loihi=loihi2_is_available,\n",
    "                                      spike_exp=4,    # This sets the decimal/fraction precision of spike message to 4 bits\n",
    "                                      num_steps=100)  # Number of frames to perform inference on\n",
    "\n",
    "# Pre and post processing parameters\n",
    "pre_args = slayer.utils.dotdict(input_mean=np.array([0.485, 0.456, 0.406]),  # Input normalization mean\n",
    "                                input_std=np.array([0.229, 0.224, 0.225]))   #                     & std\n",
    "post_args = slayer.utils.dotdict(anchors=np.array([(0.28, 0.22),  # YOLO head's anchor preset scales\n",
    "                                                   (0.38, 0.48),\n",
    "                                                   (0.90, 0.78)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9ad4b-6c01-4f85-9413-8761aa725f07",
   "metadata": {},
   "source": [
    "## Load YOLO-KP network\n",
    "\n",
    "Loading the network is a simple NetX call on the trained model computational graph. It will generate an hierarchical lava process representing the entire YOLO-KP network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21049ee5-398d-4c7a-8431-0f6322e747de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was trained for BDD100K dataset\n",
      "\n",
      "Network Architecture (yolo_kp):\n",
      "===============================\n",
      "|   Type   |  W  |  H  |  C  | ker | str | pad | dil | grp |delay|\n",
      "|Conv      |  224|  224|   16| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |  112|  112|   32| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   56|   56|   64| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   28|   28|  128| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   28|   28|  256| 3, 3| 1, 1| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  256| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  512| 3, 3| 1, 1| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  256| 1, 1| 1, 1| 0, 0| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  512| 3, 3| 1, 1| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|   48| 1, 1| 1, 1| 0, 0| 1, 1|    1|False|\n"
     ]
    }
   ],
   "source": [
    "net = netx.hdf5.Network(trained_folder + '/network.net',\n",
    "                        skip_layers=1,  # First layer does delta encoding. We will only send it's sparsified output\n",
    "                        input_message_bits=16,  # This means the network takes 16bit graded spike input\n",
    "                        spike_exp=inference_args.spike_exp)\n",
    "print(f'The model was trained for {model_args.dataset} dataset')\n",
    "print(f'\\nNetwork Architecture ({model_args.model}):'); print('=' * (24 + len(model_args.model))); print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afeb7d-53ba-472f-9ef4-967d8043da14",
   "metadata": {},
   "source": [
    "## Dataset and input source\n",
    "\n",
    "The dataset is the same module that is used for training. It is wrapped around by a data generator module that will generate an individual frame and its annotation at every time-step. The data generator also takes care of data normalization using the mean and variance supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eaacf43-0ce3-4e95-b331-59c6f609acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = obd.dataset.BDD(root=model_args.path, dataset='track',\n",
    "                           train=False, randomize_seq=False,\n",
    "                           seq_len=inference_args.num_steps)\n",
    "data_gen = DataGenerator(dataset=test_set, mean=pre_args.input_mean, std=pre_args.input_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeace54f",
   "metadata": {},
   "source": [
    "## Input preprocessing and encoding\n",
    "\n",
    "The input preprocessing involves quantization of the numeric data making it ready to be processed on the chip. A fractional representation of 6 bits was used in the weight of the network during training (`weight_exp`) which is also accounted for during quantization.\n",
    "\n",
    "The quantized input frames are then processed the the lava processes `sender`, `encoder` (and `inp_adapter` for Loihi execution) which will be connected in a sequential manner below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize = netx.modules.Quantize(exp=6)  # convert to fixed point representation with 6 bit of fraction\n",
    "sender = io.injector.Injector(shape=net.inp.shape, buffer_size=128)\n",
    "encoder = DeltaEncoder(vth=net.net_config['layer'][0]['neuron']['vThMant'],\n",
    "                       spike_exp=net.spike_exp,\n",
    "                       num_bits=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc614a5",
   "metadata": {},
   "source": [
    "## Output decoding and post processing\n",
    "\n",
    "The output of YOLO-KP goes through (`state_adapter` for Loihi execution), `receiver` and `dequantizer` lava processes which will be connected sequentially. The raw outputs needs to be processed using `yolo_predictor` which transforms the input to the actual bounding box predictions of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449d0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver = io.extractor.Extractor(shape=net.out.shape, buffer_size=128)\n",
    "dequantize = netx.modules.Dequantize(exp=net.spike_exp + 12, num_raw_bits=24)\n",
    "yolo_predictor = YOLOPredictor(anchors=post_args.anchors, clamp_max=model_args.clamp_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3164b-8d41-402f-adac-e39264f88e47",
   "metadata": {},
   "source": [
    "## Output visualization\n",
    "\n",
    "`YOLOMonitor` is a flexible output visualization and evaluation module. It continuously evaluates the mAP score of the output predictions. It can also be passed a callable function that can be used to display. In this case it is a basic iPython display routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571c9df9-971f-4eb3-aa45-633081fd9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_visualizer(annotated_frame, map_score, frame_idx):\n",
    "    # clear_output(wait=True)\n",
    "    # display(annotated_frame)\n",
    "    # print(f'Processed frame {frame_idx}')\n",
    "    # print(f'Object detection mAP@0.5 = {map_score:.2f}')\n",
    "    print(f'\\rProcessed frame {frame_idx}: Object detection mAP@0.5 = {map_score:.2f}', end='')\n",
    "    \n",
    "yolo_monitor = YOLOMonitor(viz_fx=output_visualizer, class_list=test_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba7ca7",
   "metadata": {},
   "source": [
    "## Data buffers / delays\n",
    "\n",
    "There is a latency in the prediction equal to the number of layers the network has and the encoding step. Two FIFO buffers are used to synchronize the input frame and target annotation with the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9242a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_buffer = netx.modules.FIFO(depth=len(net) + 1)\n",
    "# annotation_buffer = netx.modules.FIFO(depth=len(net) + 1)\n",
    "frame_buffer = netx.modules.FIFO(depth=len(net))\n",
    "annotation_buffer = netx.modules.FIFO(depth=len(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3b7d2",
   "metadata": {},
   "source": [
    "# Connect Lava processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2571441-fd3c-447c-8e5d-703e23d313d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_args.loihi:\n",
    "    from lava.magma.core.process.ports.connection_config import ConnectionConfig, SpikeIOInterface, SpikeIOMode\n",
    "    connection_config = ConnectionConfig()\n",
    "    connection_config.interface = SpikeIOInterface.ETHERNET\n",
    "    connection_config.spike_io_mode = SpikeIOMode.FREE_RUNNING\n",
    "    connection_config.ethernet_chip_id = (2, 2, 1)\n",
    "    connection_config.ethernet_chip_idx = 12\n",
    "    connection_config.ethernet_mac_address = \"0x80615f11b9d6\"\n",
    "\n",
    "    # from lava.magma.core.process.ports import connection_config as conn_cfg\n",
    "    # print('BEFORE')\n",
    "    # print(conn_cfg.default_config)\n",
    "    # # conn_cfg.default_config = connection_config\n",
    "    # conn_cfg.default_config.interface = SpikeIOInterface.ETHERNET\n",
    "    # conn_cfg.default_config.spike_io_mode = SpikeIOMode.FREE_RUNNING\n",
    "    # conn_cfg.default_config.ethernet_chip_id = (2, 2, 1)\n",
    "    # conn_cfg.default_config.ethernet_chip_idx = 12\n",
    "    # conn_cfg.default_config.ethernet_mac_address = \"0x80615f11b9d6\"\n",
    "    # from lava.magma.core.process.ports import connection_config as cc\n",
    "    # print('AFTER')\n",
    "    # print(cc.default_config)\n",
    "    \n",
    "    # sender.out_port.connect(encoder.a_in)\n",
    "    # # encoder.s_out.connect(inp_adapter.inp)\n",
    "    # # inp_adapter.out.connect(net.inp)\n",
    "    # # encoder.s_out.connect(net.inp, connection_config)  # connection_config does not get propagated to nested port\n",
    "    # encoder.s_out.connect(net.in_layer.synapse.s_in, connection_config)\n",
    "    sender.out_port.connect(net.in_layer.synapse.s_in, connection_config)\n",
    "    # state_adapter.connect_var(net.out_layer.neuron.sigma)\n",
    "    # state_adapter.out.connect(receiver.in_port)\n",
    "    # net.out.connect(receiver.in_port)\n",
    "    net.out_layer.neuron.s_out.connect(receiver.in_port, connection_config)\n",
    "    \n",
    "    # sender.out_port.connect(net.in_layer.synapse.s_in)\n",
    "    # net.out_layer.neuron.s_out.connect(receiver.in_port)\n",
    "else:\n",
    "    # sender.out_port.connect(encoder.a_in)\n",
    "    # encoder.s_out.connect(net.inp)\n",
    "    sender.out_port.connect(net.inp)\n",
    "    net.out.connect(receiver.in_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67623b71",
   "metadata": {},
   "source": [
    "# Setup execution\n",
    "\n",
    "The network is run in _non-blocking mode_. Note the `blocking=False` argument below. In non-blocking mode we can start running the lava process and do other computations in parallel. Here we will preprocess the data, send it to lava network using `sender` (`lava.proc.io.injector.Injector` instance), receive data from lava using `receiver` (`lava.proc.io.extractor.Extractor` instance), and perform additional processing, while the Lava network is running in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7baa7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = inference_args.num_steps\n",
    "run_condition = RunSteps(num_steps=num_steps, blocking=False)\n",
    "\n",
    "from lava.magma.core.model.py.model import PyLoihiModelToPyAsyncModel\n",
    "\n",
    "exception_proc_model_map = {# io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelDense,\n",
    "                            io.encoder.DeltaEncoder: PyLoihiModelToPyAsyncModel(io.encoder.PyDeltaEncoderModelDense),\n",
    "                            io.injector.Injector: io.injector.PyLoihiInjectorModelAsync,\n",
    "                            io.extractor.Extractor: io.extractor.PyLoihiExtractorModelAsync,\n",
    "}\n",
    "\n",
    "# exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelDense}\n",
    "\n",
    "if inference_args.loihi:\n",
    "    # exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelSparse}\n",
    "    run_config = Loihi2HwCfg(exception_proc_model_map=exception_proc_model_map)\n",
    "else:\n",
    "    # exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelDense}\n",
    "    run_config = Loihi2SimCfg(select_tag='fixed_pt',\n",
    "                              exception_proc_model_map=exception_proc_model_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33bdc8",
   "metadata": {},
   "source": [
    "# Run YOLO-KP inference\n",
    "\n",
    "The following will compile and run the Lava network.\n",
    "\n",
    "> ℹ️ The network is large. It will take a while for the compilation to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9230a375-7e83-4b8d-a668-1ace4d503d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_frames = []\n",
    "# spikes = 0\n",
    "# for t in range(num_steps):\n",
    "#     frame, annotation, raw_frame = data_gen()\n",
    "#     frame = quantize(frame)\n",
    "#     frame = encoder(frame)\n",
    "#     spikes += np.sum(frame != 0)\n",
    "#     processed_frames.append((frame, annotation, raw_frame))\n",
    "\n",
    "# spikes = spikes / num_steps\n",
    "\n",
    "# # Avg spikes per time-step = 344288.45\n",
    "\n",
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c557db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning converged after iteration=3\n",
      "Per core utilization:\n",
      "-------------------------------------------------------------------------\n",
      "| AxonIn |NeuronGr| Neurons|Synapses| AxonMap| AxonMem|  Total |  Cores |\n",
      "|-----------------------------------------------------------------------|\n",
      "|   0.01%|  25.00%|  65.64%|  19.20%|  16.80%|   0.00%|  42.26%|       4|Conv(4, 14, 48)\n",
      "|   0.01%|  12.50%|  87.52%|  86.40%|   0.35%|   0.17%|  87.47%|      32|Conv(8, 7, 64)\n",
      "|   0.01%|  12.50%|  87.52%|  67.20%|   0.09%|   0.35%|  72.04%|      14|Conv(2, 7, 256)\n",
      "|   0.01%|  12.50%|  87.52%|  86.40%|   0.35%|   0.35%|  87.61%|      32|Conv(8, 7, 64)\n",
      "|   0.01%|  12.50%|  87.52%|  72.00%|   0.35%|   2.80%|  78.05%|      16|Conv(8, 7, 64)\n",
      "|   0.01%|  12.50%|  87.52%|  79.20%|   0.17%|   0.17%|  81.57%|      56|Conv(4, 7, 128)\n",
      "|   0.01%|  12.50%|  87.52%|  39.60%|   0.17%|   0.35%|  50.03%|      28|Conv(4, 7, 128)\n",
      "|   0.01%|  12.50%|  87.52%|  10.80%|   0.35%|   0.17%|  26.99%|      56|Conv(4, 14, 64)\n",
      "|   0.01%|  12.50%|  87.52%|   3.60%|   0.70%|   0.35%|  21.65%|     112|Conv(8, 14, 32)\n",
      "|   0.01%|  12.50%|  87.52%|   0.34%|   1.40%|   0.70%|  19.88%|     224|Conv(8, 28, 16)\n",
      "|-----------------------------------------------------------------------|\n",
      "| Total                                                        |     574|\n",
      "-------------------------------------------------------------------------\n",
      "WARNING: In the convolution layer of dimension (224, 224, 16) some convolution results might not be exact. Some convolution spikes originating from x_in=n*256-1 and its neighbours might get dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/n3b/n3board.py:77: UserWarning: Loihi generation overriden by environment variable LOIHI_GEN=N3C1\n",
      "  warnings.warn(\"Loihi generation overriden by environment variable LOIHI_GEN={}\".format(os.environ[\"LOIHI_GEN\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:  Running in non-slurm environment on : ncl-gdc-vpx-01.zpn.intel.com\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Initializing PAC193X registers to defaults.\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:  Connecting to ncl-gdc-vpx-01.zpn.intel.com:43199\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Host server up..............Done 4.51s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Mapping chipIds.............Done 0.06ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Mapping coreIds.............Done 6.22ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Partitioning neuron groups..Done 0.23s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Mapping axons...............Done 1.03s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Configuring Spike Block.....Done 0.16ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Writes SpikeIO Config to FileDone 3.61ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Initializes Python MQ.......Done 1.35s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Partitioning MPDS...........Done 0.15s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Compiling Embedded snips....Done 5.34s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Compiling Host snips........Done 0.07ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Compiling Register Probes...Done 0.10ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Compiling Spike Probes......Done 0.01ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=0 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip0_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=0 cpu=1 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip0_cpu1.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=1 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip1_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=2 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip2_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=3 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip3_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=4 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip4_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=5 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip5_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=6 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip6_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=7 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip7_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=8 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip8_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=9 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip9_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=10 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip10_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=11 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip11_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=12 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/arch/base/pre_execution/../../../../temp/b35009c9-b025-11ee-8baa-b1b1edf4b3a9/launcher_chip12_cpu0.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=13 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/driver/../bin/armv7l-N3C1/x86/idle_chip.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=14 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/driver/../bin/armv7l-N3C1/x86/idle_chip.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Args chip=15 cpu=0 /home/sshresth/lava-vpx/frameworks.ai.nx.nxsdk/nxcore/driver/../bin/armv7l-N3C1/x86/idle_chip.bin --spike-block-id=0,0,0,p --spike-block-id=2,2,1,p --chips=13 --remote-relay=0 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Nx...\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=13 msg=00018114 00000f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=15 msg=00018114 00000f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=14 msg=00018114 00000f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Booting up..................Done 5.00s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Encoding probes.............Done 0.01ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Transferring probes.........Done 0.03s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Configuring registers.......Done 202.09s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Transferring spikes.........Done 0.00ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=2 msg=00018114 00daff60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=3 msg=00018114 00daff60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=4 msg=00018114 00daff60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=5 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=6 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=7 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=8 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=9 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=10 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=11 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=0 msg=00018114 00daff60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=1 msg=00018114 00daff60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=12 msg=00018114 00d00f60 \n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=14 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=15 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=13 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Executing...................Done 1.70s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:      Processing timeseries.......Done 0.04ms\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mDRV\u001b[0m\u001b[0m:  Executor: 100 timesteps.........Done 207.06s\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Execution has not started yet or has finished.\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Stopping Execution : at 100\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=0 cpu=1 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=1 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=2 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=3 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=4 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=5 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=6 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=7 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=8 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=9 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=10 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=11 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=12 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  chip=0 cpu=0 halted, status=0x0\n",
      "\u001b[1;30m\u001b[1;30mINFO\u001b[0m\u001b[0m:\u001b[34m\u001b[34mHST\u001b[0m\u001b[0m:  Connection to ncl-gdc-vpx-01.zpn.intel.com closed.\n"
     ]
    }
   ],
   "source": [
    "sender._log_config.level = logging.INFO\n",
    "sender.run(condition=run_condition, run_cfg=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eadb5789-2ec9-46e6-95e7-c35464b0f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "def sender_thread(sender, send_frame_queue, num_steps):\n",
    "    for _ in range(num_steps):\n",
    "        frame = send_frame_queue.get()\n",
    "        sender.send(frame)        # This sends the input frame to the Lava network\n",
    "\n",
    "def receiver_thread(receiver, recv_frame_queue, num_steps):\n",
    "    for t in range(num_steps):\n",
    "        out = receiver.receive()  # This receives the output from the Lava network\n",
    "        out = dequantize(out)\n",
    "        \n",
    "        annotation, raw_frame = recv_frame_queue.get()\n",
    "        input_frame = frame_buffer(raw_frame)\n",
    "        gt_ann = annotation_buffer(annotation)\n",
    "        if input_frame is not None:  # valid output from FIFO buffer\n",
    "            predictions = yolo_predictor(out)\n",
    "            pred_bbox = nms(predictions)\n",
    "            gt_bbox = obd.bbox.utils.tensor_from_annotation(gt_ann).cpu().data.numpy()\n",
    "            yolo_monitor(input_frame, gt_bbox, pred_bbox)\n",
    "        else:\n",
    "            print(f'Frame {t} queued in pipeline.', end='\\r')\n",
    "\n",
    "s_q = queue.Queue()\n",
    "r_q = queue.Queue()\n",
    "s_th = threading.Thread(target=sender_thread, args=(sender, s_q, num_steps))\n",
    "r_th = threading.Thread(target=receiver_thread, args=(receiver, r_q, num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb2fbc3-c069-40be-9124-2e4db5d06f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Arguments passed to program: 8\n",
      " eth_ready_shm_name: eth_ready_1310 ready_shm_name: ready_68391 stop_shm_name: stop_33525 interface_name: enp2s0 time_bucket_shm_name: time_buckets_1310 num_counters_per_bucket: 9409 num_time_buckets: 65536\n",
      "Initialize Eth Complete\n",
      "Initialize PCAP Complete\n",
      "Init Snip Signal Received \u0001\n",
      "Wrote 1 to Ready Memory\n",
      "Listening for Data\n",
      "\n",
      "Processed frame 90: Object detection mAP@0.5 = 0.28End of Ethernet Snooper Program\n",
      "Processed frame 90: Object detection mAP@0.5 = 0.28"
     ]
    }
   ],
   "source": [
    "s_th.start()\n",
    "r_th.start()\n",
    "\n",
    "for t in range(num_steps):\n",
    "    frame, annotation, raw_frame = data_gen()\n",
    "    frame = quantize(frame)\n",
    "    frame = encoder(frame)\n",
    "    \n",
    "    s_q.put(frame)\n",
    "    r_q.put((annotation, raw_frame))\n",
    "\n",
    "# for frame, annotation, raw_frame in processed_frames:\n",
    "#     s_q.put(frame)\n",
    "#     r_q.put((annotation, raw_frame))\n",
    "\n",
    "s_th.join()\n",
    "r_th.join()\n",
    "\n",
    "sender.wait()\n",
    "sender.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62468f2-950f-40e7-968a-1ea1e7d2059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBest result, everything except visualization\\nINFO:DRV:      Executing...................Done 1.91s\\nINFO:DRV:      Processing timeseries.......Done 0.03ms\\nINFO:DRV:  Executor: 100 timesteps.........Done 204.94s\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimization plans\n",
    "# - ✅ Make delta encoding a python call\n",
    "# - YOLO predictions and NMS on a separate thread\n",
    "# - FIFO slack based output visualization\n",
    "\n",
    "# TODO:\n",
    "# - Verify consistency between runs\n",
    "\n",
    "'''\n",
    "With pre-loading pre-processed data; no post processing\n",
    "INFO:DRV:      Executing...................Done 1.61s\n",
    "INFO:DRV:      Processing timeseries.......Done 0.02ms\n",
    "INFO:DRV:  Executor: 100 timesteps.........Done 206.99s\n",
    "'''\n",
    "\n",
    "'''\n",
    "Best result, everything except visualization\n",
    "INFO:DRV:      Executing...................Done 1.70s (1.90s, 1.64s)\n",
    "INFO:DRV:      Processing timeseries.......Done 0.04ms\n",
    "INFO:DRV:  Executor: 100 timesteps.........Done 207.06s\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
