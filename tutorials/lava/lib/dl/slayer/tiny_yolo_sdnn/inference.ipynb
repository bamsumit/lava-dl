{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-quilt",
   "metadata": {},
   "source": [
    "# YOLO Sigma-Delta Neural Network (SDNN) Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lava.lib.dl import slayer\n",
    "from lava.lib.dl.slayer import obd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-willow",
   "metadata": {},
   "source": [
    "# Load Inference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = slayer.utils.dotdict(load='trained/network.pt')\n",
    "trained_folder = os.path.dirname(args.load)\n",
    "print(trained_folder)\n",
    "\n",
    "with open(trained_folder + '/args.txt', 'rt') as f:\n",
    "    model_args = slayer.utils.dotdict(yaml.safe_load(f))\n",
    "    for (k, v) in model_args.items():\n",
    "        if k not in args.keys():\n",
    "            args[k] = v\n",
    "            \n",
    "print('Using GPUs {}'.format(args.gpu))\n",
    "device = torch.device('cuda:{}'.format(args.gpu[0]))\n",
    "classes_output = {'BDD100K': 11}\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-spring",
   "metadata": {},
   "source": [
    "# Load Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(args.gpu) == 1:\n",
    "        net = obd.models.tiny_yolov3_str.Network(threshold=model_args.threshold,\n",
    "                        tau_grad=model_args.tau_grad,\n",
    "                        scale_grad=model_args.scale_grad,\n",
    "                        num_classes=classes_output[model_args.dataset],\n",
    "                        clamp_max=model_args.clamp_max).to(device)\n",
    "        module = net\n",
    "else:\n",
    "        net = torch.nn.DataParallel(obd.models.tiny_yolov3_str.Network(threshold=model_args.threshold,\n",
    "                                        tau_grad=model_args.tau_grad,\n",
    "                                        scale_grad=model_args.scale_grad,\n",
    "                                        num_classes=classes_output[model_args.dataset],\n",
    "                                        clamp_max=model_args.clamp_max).to(device),\n",
    "                                device_ids=args.gpu)\n",
    "        module = net.module\n",
    "\n",
    "module.init_model((448, 448))\n",
    "module.load_state_dict(torch.load(args.load))\n",
    "\n",
    "yolo_target = obd.YOLOtarget(anchors=net.anchors,\n",
    "                             scales=net.scale,\n",
    "                             num_classes=net.num_classes,\n",
    "                             ignore_iou_thres=model_args.tgt_iou_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3adf1",
   "metadata": {},
   "source": [
    "# Load Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = obd.dataset.BDD(root=args.path, dataset='track', train=False, randomize_seq=False, seq_len=60)\n",
    "\n",
    "test_loader = DataLoader(test_set,\n",
    "                        batch_size=args.b,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=yolo_target.collate_fn,\n",
    "                        num_workers=args.num_workers,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562ca5d",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "stats = slayer.utils.LearningStats(accuracy_str='AP@0.5')\n",
    "t_st = datetime.now()\n",
    "ap_stats = obd.bbox.metrics.APstats(iou_threshold=0.5)\n",
    "all_counts = []\n",
    "for i, (inputs, targets, bboxes) in enumerate(test_loader):\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        predictions, counts = net(inputs)\n",
    "        all_counts.append(counts.cpu().data.numpy())\n",
    "\n",
    "        T = inputs.shape[-1]\n",
    "        \n",
    "        predictions = [obd.bbox.utils.non_maximum_suppression(predictions[..., t]) for t in range(T)]\n",
    "\n",
    "        for t in range(T):\n",
    "            ap_stats.update(predictions[t], bboxes[t])\n",
    "\n",
    "        # stats.testing.loss_sum += loss.item() * inputs.shape[0]\n",
    "        stats.testing.num_samples += inputs.shape[0]\n",
    "        stats.testing.correct_samples = ap_stats[:] * stats.testing.num_samples\n",
    "\n",
    "        processed = i * test_loader.batch_size\n",
    "        total = len(test_loader.dataset)\n",
    "        time_elapsed = (datetime.now() - t_st).total_seconds()\n",
    "        samples_sec = time_elapsed / (i + 1) / test_loader.batch_size\n",
    "        header_list = [f'Test: [{processed}/{total} '\n",
    "                        f'({100.0 * processed / total:.0f}%)]']\n",
    "        header_list += ['Event Rate: ['\n",
    "                        + ', '.join([f'{c.item():.2f}'\n",
    "                                        for c in counts[0]]) + ']']\n",
    "        \n",
    "        print(f'\\r{i}, {samples_sec:3f}samples/sec {stats}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386b5ff",
   "metadata": {},
   "source": [
    "# Results: Output vs groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec430f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "obd.bbox.utils.create_video(inputs, bboxes, predictions, 'trained/test', test_set.classes)\n",
    "\n",
    "Video(\"./trained/test.mp4\", embed=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
